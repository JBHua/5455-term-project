
Start -- Nov 10 16:33:01 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:33:01	Initing processor, tokenizer, and speaker_model
16:33:04	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:36:31	Finish Loading Remote Dataset. Length of dataset: 8387
16:36:31	Start Setting Sampling Rate to 16 kHz...
16:36:31	Setting Sampling Rate Successfully
16:36:31	Exception: <class 'TypeError'>. filter_and_prepare_dataset() missing 1 required positional argument: 'dataset'. Traceback: <traceback object at 0x7f1be4598dc0>

Start -- Nov 10 16:36:46 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:36:46	Initializing processor, tokenizer, and speaker_model
16:36:47	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:37:12	Finish Loading Remote Dataset. Length of dataset: 8387
16:37:12	Start Setting Sampling Rate to 16 kHz...
16:37:12	Setting Sampling Rate Successfully
16:37:12	Start Filtering Short Data
16:37:12	8358 data entries left after filtering
16:37:12	Start Preparing Dataset
16:38:41	KeyboardInterrupt detected. Exiting...

Start -- Nov 10 16:38:47 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:38:47	Initializing processor, tokenizer, and speaker_model
16:38:48	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:39:13	Finish Loading Remote Dataset. Length of dataset: 8387
16:39:13	Start Setting Sampling Rate to 16 kHz...
16:39:13	Setting Sampling Rate Successfully
16:39:13	Start Filtering Short Data
16:39:13	8358 data entries left after filtering
16:39:13	Start Preparing Dataset
16:40:04	Exception: <class 'multiprocess.context.TimeoutError'>. . Traceback: <traceback object at 0x7f1327d49f80>

Start -- Nov 10 16:40:08 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:40:08	Initializing processor, tokenizer, and speaker_model
16:40:09	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:40:34	Finish Loading Remote Dataset. Length of dataset: 8387
16:40:34	Start Setting Sampling Rate to 16 kHz...
16:40:34	Setting Sampling Rate Successfully
16:40:34	Start Filtering Short Data
16:40:34	8358 data entries left after filtering
16:40:34	Start Preparing Dataset
16:41:04	Exception: <class 'multiprocess.context.TimeoutError'>. . Traceback: <traceback object at 0x7fa037fc5100>

Start -- Nov 10 16:41:07 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:41:07	Initializing processor, tokenizer, and speaker_model
16:41:08	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:41:33	Finish Loading Remote Dataset. Length of dataset: 8387
16:41:33	Start Setting Sampling Rate to 16 kHz...
16:41:33	Setting Sampling Rate Successfully
16:41:33	Start Filtering Short Data
16:41:33	8358 data entries left after filtering
16:41:33	Start Preparing Dataset
16:47:00	Preparing dataset finished successfully
16:47:00	Start Filtering Long Data
16:47:00	6329 data entries left after filtering
16:47:00	save_processed_dataset is True. Saving processed dataset to dir: ./data/


Start -- Nov 10 16:50:43 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:50:43	Initializing processor, tokenizer, and speaker_model
16:50:44	Using Locally Processed Dataset. Skip Processing...
16:50:44	Failed to load local dataset. Please double check file exists and path is correct

Start -- Nov 10 16:51:12 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:51:12	Initializing processor, tokenizer, and speaker_model
16:51:12	Using Locally Processed Dataset. Skip Processing...
16:51:12	Failed to load local dataset. Please double check file exists and path is correct

Start -- Nov 10 16:52:45 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:52:45	Initializing processor, tokenizer, and speaker_model
16:52:45	Using Locally Processed Dataset. Skip Processing...
16:52:45	Failed to load local dataset. Please double check file exists and path is correct. You are trying to load a dataset that was saved using `save_to_disk`. Please use `load_from_disk` instead.

Start -- Nov 10 16:53:20 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:53:20	Initializing processor, tokenizer, and speaker_model
16:53:21	Using Locally Processed Dataset. Skip Processing...


Start -- Nov 10 17:42:43 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
17:42:43	Initializing processor, tokenizer, and speaker_model
17:43:04	Using Locally Processed Dataset. Skip Processing...
17:43:04	Generating Seq2SeqTrainer Arguments
17:43:04	Generating Seq2SeqTrainer
17:44:39	Exception: <class 'huggingface_hub.utils._errors.BadRequestError'>.  (Request ID: Root=1-654eb213-4bedca92381c9f61443bf392;dfd56855-90c4-42ec-bffa-f445e26543e3)

Bad request for commit endpoint:
"language[0]" with value "en_accented" is not valid. It must be an ISO 639-1, 639-2 or 639-3 code (two/three letters), or a special value like "code", "multilingual". If you want to use BCP-47 identifiers, you can specify them in language_bcp47.
"tags[0]" is not allowed to be empty. Traceback: <traceback object at 0x7eff3ca4d400>

Start -- Nov 10 17:46:04 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
17:46:04	Initializing processor, tokenizer, and speaker_model
17:46:06	Using Locally Processed Dataset. Skip Processing...
17:46:06	Generating Seq2SeqTrainer Arguments
17:46:06	Generating Seq2SeqTrainer
17:46:08	Start Training...
18:44:14	Start Saving the model...
18:44:17	Exception: <class 'KeyError'>. "Column test not in the dataset. Current columns in the dataset: ['input_ids', 'labels', 'speaker_embeddings']". Traceback: <traceback object at 0x7fc01cdca2c0>

Start -- Nov 10 20:53:15 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
20:53:15	Initializing processor, tokenizer, and speaker_model
20:53:17	Using Locally Processed Dataset. Skip Processing...
20:53:17	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper20:53:15
20:53:17	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper20:53:15'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7fca353cd380>

Start -- Nov 10 20:54:20 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
20:54:20	Initializing processor, tokenizer, and speaker_model
20:54:23	Using Locally Processed Dataset. Skip Processing...
20:54:23	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper20:54:20
20:54:23	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper20:54:20'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7fd3a2a8e1c0>

Start -- Nov 10 21:05:37 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:05:37	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:05:39	Using Locally Processed Dataset. Skip Processing...
21:05:39	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper21:03:24
21:05:51	KeyboardInterrupt detected. Exiting...

Start -- Nov 10 21:06:31 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:06:31	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:06:33	Using Locally Processed Dataset. Skip Processing...
21:06:33	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper21:06:31
21:06:36	Exception: <class 'IndexError'>. list index out of range. Traceback: <traceback object at 0x7fb5cb4a8380>

Start -- Nov 10 21:07:53 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:07:53	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:07:55	Using Locally Processed Dataset. Skip Processing...
21:07:55	Loading Locally Stored Model from: ./model/
21:08:01	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper21:07:53'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7fba6c0c8180>

Start -- Nov 10 21:08:30 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:08:30	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:08:32	Using Locally Processed Dataset. Skip Processing...
21:08:32	Loading Locally Stored Model from: ./model/
21:09:18	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper21:08:30'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7f064e128240>

Start -- Nov 10 21:10:48 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:10:48	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:10:50	Using Locally Processed Dataset. Skip Processing...
21:10:50	Loading Locally Stored Model from: ./model/
21:10:51	Using model: ./model/trained_yifanhua-threadripper17:46:04
21:10:51	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper21:10:48'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7f3dcffd6b40>

Start -- Nov 10 21:11:12 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:11:12	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:11:14	Using Locally Processed Dataset. Skip Processing...
21:11:14	Loading Locally Stored Model from: ./model/
21:11:16	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:23:19 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:23:19	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:23:22	Using Locally Processed Dataset. Skip Processing...
21:23:22	Exception: <class 'NameError'>. name 'selected_model' is not defined. Traceback: <traceback object at 0x7fb9d05c8c00>

Start -- Nov 10 21:23:42 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:23:42	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:23:44	Using Locally Processed Dataset. Skip Processing...
21:23:44	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:24:20 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:24:20	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:24:23	Using Locally Processed Dataset. Skip Processing...
21:24:23	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:24:40 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:24:40	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:24:43	Using Locally Processed Dataset. Skip Processing...
21:24:43	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:25:05 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:25:05	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:25:07	Using Locally Processed Dataset. Skip Processing...
21:25:07	Using model: ./model/trained_yifanhua-threadripper17:46:04

