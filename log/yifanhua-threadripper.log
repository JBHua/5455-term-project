
Start -- Nov 10 16:33:01 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:33:01	Initing processor, tokenizer, and speaker_model
16:33:04	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:36:31	Finish Loading Remote Dataset. Length of dataset: 8387
16:36:31	Start Setting Sampling Rate to 16 kHz...
16:36:31	Setting Sampling Rate Successfully
16:36:31	Exception: <class 'TypeError'>. filter_and_prepare_dataset() missing 1 required positional argument: 'dataset'. Traceback: <traceback object at 0x7f1be4598dc0>

Start -- Nov 10 16:36:46 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:36:46	Initializing processor, tokenizer, and speaker_model
16:36:47	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:37:12	Finish Loading Remote Dataset. Length of dataset: 8387
16:37:12	Start Setting Sampling Rate to 16 kHz...
16:37:12	Setting Sampling Rate Successfully
16:37:12	Start Filtering Short Data
16:37:12	8358 data entries left after filtering
16:37:12	Start Preparing Dataset
16:38:41	KeyboardInterrupt detected. Exiting...

Start -- Nov 10 16:38:47 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:38:47	Initializing processor, tokenizer, and speaker_model
16:38:48	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:39:13	Finish Loading Remote Dataset. Length of dataset: 8387
16:39:13	Start Setting Sampling Rate to 16 kHz...
16:39:13	Setting Sampling Rate Successfully
16:39:13	Start Filtering Short Data
16:39:13	8358 data entries left after filtering
16:39:13	Start Preparing Dataset
16:40:04	Exception: <class 'multiprocess.context.TimeoutError'>. . Traceback: <traceback object at 0x7f1327d49f80>

Start -- Nov 10 16:40:08 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:40:08	Initializing processor, tokenizer, and speaker_model
16:40:09	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:40:34	Finish Loading Remote Dataset. Length of dataset: 8387
16:40:34	Start Setting Sampling Rate to 16 kHz...
16:40:34	Setting Sampling Rate Successfully
16:40:34	Start Filtering Short Data
16:40:34	8358 data entries left after filtering
16:40:34	Start Preparing Dataset
16:41:04	Exception: <class 'multiprocess.context.TimeoutError'>. . Traceback: <traceback object at 0x7fa037fc5100>

Start -- Nov 10 16:41:07 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:41:07	Initializing processor, tokenizer, and speaker_model
16:41:08	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
16:41:33	Finish Loading Remote Dataset. Length of dataset: 8387
16:41:33	Start Setting Sampling Rate to 16 kHz...
16:41:33	Setting Sampling Rate Successfully
16:41:33	Start Filtering Short Data
16:41:33	8358 data entries left after filtering
16:41:33	Start Preparing Dataset
16:47:00	Preparing dataset finished successfully
16:47:00	Start Filtering Long Data
16:47:00	6329 data entries left after filtering
16:47:00	save_processed_dataset is True. Saving processed dataset to dir: ./data/


Start -- Nov 10 16:50:43 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:50:43	Initializing processor, tokenizer, and speaker_model
16:50:44	Using Locally Processed Dataset. Skip Processing...
16:50:44	Failed to load local dataset. Please double check file exists and path is correct

Start -- Nov 10 16:51:12 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:51:12	Initializing processor, tokenizer, and speaker_model
16:51:12	Using Locally Processed Dataset. Skip Processing...
16:51:12	Failed to load local dataset. Please double check file exists and path is correct

Start -- Nov 10 16:52:45 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:52:45	Initializing processor, tokenizer, and speaker_model
16:52:45	Using Locally Processed Dataset. Skip Processing...
16:52:45	Failed to load local dataset. Please double check file exists and path is correct. You are trying to load a dataset that was saved using `save_to_disk`. Please use `load_from_disk` instead.

Start -- Nov 10 16:53:20 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
16:53:20	Initializing processor, tokenizer, and speaker_model
16:53:21	Using Locally Processed Dataset. Skip Processing...


Start -- Nov 10 17:42:43 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
17:42:43	Initializing processor, tokenizer, and speaker_model
17:43:04	Using Locally Processed Dataset. Skip Processing...
17:43:04	Generating Seq2SeqTrainer Arguments
17:43:04	Generating Seq2SeqTrainer
17:44:39	Exception: <class 'huggingface_hub.utils._errors.BadRequestError'>.  (Request ID: Root=1-654eb213-4bedca92381c9f61443bf392;dfd56855-90c4-42ec-bffa-f445e26543e3)

Bad request for commit endpoint:
"language[0]" with value "en_accented" is not valid. It must be an ISO 639-1, 639-2 or 639-3 code (two/three letters), or a special value like "code", "multilingual". If you want to use BCP-47 identifiers, you can specify them in language_bcp47.
"tags[0]" is not allowed to be empty. Traceback: <traceback object at 0x7eff3ca4d400>

Start -- Nov 10 17:46:04 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
17:46:04	Initializing processor, tokenizer, and speaker_model
17:46:06	Using Locally Processed Dataset. Skip Processing...
17:46:06	Generating Seq2SeqTrainer Arguments
17:46:06	Generating Seq2SeqTrainer
17:46:08	Start Training...
18:44:14	Start Saving the model...
18:44:17	Exception: <class 'KeyError'>. "Column test not in the dataset. Current columns in the dataset: ['input_ids', 'labels', 'speaker_embeddings']". Traceback: <traceback object at 0x7fc01cdca2c0>

Start -- Nov 10 20:53:15 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
20:53:15	Initializing processor, tokenizer, and speaker_model
20:53:17	Using Locally Processed Dataset. Skip Processing...
20:53:17	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper20:53:15
20:53:17	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper20:53:15'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7fca353cd380>

Start -- Nov 10 20:54:20 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
20:54:20	Initializing processor, tokenizer, and speaker_model
20:54:23	Using Locally Processed Dataset. Skip Processing...
20:54:23	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper20:54:20
20:54:23	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper20:54:20'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7fd3a2a8e1c0>

Start -- Nov 10 21:05:37 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:05:37	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:05:39	Using Locally Processed Dataset. Skip Processing...
21:05:39	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper21:03:24
21:05:51	KeyboardInterrupt detected. Exiting...

Start -- Nov 10 21:06:31 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:06:31	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:06:33	Using Locally Processed Dataset. Skip Processing...
21:06:33	Loading Locally Stored Model from: ./model/trained_yifanhua-threadripper21:06:31
21:06:36	Exception: <class 'IndexError'>. list index out of range. Traceback: <traceback object at 0x7fb5cb4a8380>

Start -- Nov 10 21:07:53 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:07:53	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:07:55	Using Locally Processed Dataset. Skip Processing...
21:07:55	Loading Locally Stored Model from: ./model/
21:08:01	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper21:07:53'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7fba6c0c8180>

Start -- Nov 10 21:08:30 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:08:30	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:08:32	Using Locally Processed Dataset. Skip Processing...
21:08:32	Loading Locally Stored Model from: ./model/
21:09:18	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper21:08:30'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7f064e128240>

Start -- Nov 10 21:10:48 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:10:48	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:10:50	Using Locally Processed Dataset. Skip Processing...
21:10:50	Loading Locally Stored Model from: ./model/
21:10:51	Using model: ./model/trained_yifanhua-threadripper17:46:04
21:10:51	Exception: <class 'huggingface_hub.utils._validators.HFValidationError'>. Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/trained_yifanhua-threadripper21:10:48'. Use `repo_type` argument if needed.. Traceback: <traceback object at 0x7f3dcffd6b40>

Start -- Nov 10 21:11:12 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:11:12	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:11:14	Using Locally Processed Dataset. Skip Processing...
21:11:14	Loading Locally Stored Model from: ./model/
21:11:16	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:23:19 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:23:19	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:23:22	Using Locally Processed Dataset. Skip Processing...
21:23:22	Exception: <class 'NameError'>. name 'selected_model' is not defined. Traceback: <traceback object at 0x7fb9d05c8c00>

Start -- Nov 10 21:23:42 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:23:42	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:23:44	Using Locally Processed Dataset. Skip Processing...
21:23:44	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:24:20 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:24:20	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:24:23	Using Locally Processed Dataset. Skip Processing...
21:24:23	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:24:40 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:24:40	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:24:43	Using Locally Processed Dataset. Skip Processing...
21:24:43	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:25:05 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:25:05	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:25:07	Using Locally Processed Dataset. Skip Processing...
21:25:07	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:31:59 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:31:59	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:32:02	Using Locally Processed Dataset. Skip Processing...
21:32:02	Using model: ./model/trained_yifanhua-threadripper17:46:04


Start -- Nov 10 21:33:06 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:33:06	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:33:10	Using Locally Processed Dataset. Skip Processing...
21:33:10	Generating Seq2SeqTrainer Arguments
21:33:10	Generating Seq2SeqTrainer
21:33:10	Start Training...
21:33:11	Exception: <class 'RuntimeError'>. cuDNN error: CUDNN_STATUS_NOT_INITIALIZED. Traceback: <traceback object at 0x7f4a3c31cdc0>

Start -- Nov 10 21:34:38 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:34:38	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:34:40	Using Locally Processed Dataset. Skip Processing...
21:34:40	Generating Seq2SeqTrainer Arguments
21:34:40	Generating Seq2SeqTrainer
21:34:40	Start Training...
21:34:43	Exception: <class 'torch.cuda.OutOfMemoryError'>. CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 7.75 GiB of which 109.75 MiB is free. Including non-PyTorch memory, this process has 5.15 GiB memory in use. Of the allocated memory 4.51 GiB is allocated by PyTorch, and 503.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF. Traceback: <traceback object at 0x7f1c6e0c6140>

Start -- Nov 10 21:38:17 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:38:17	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:38:19	Using Locally Processed Dataset. Skip Processing...
21:38:19	Generating Seq2SeqTrainer Arguments
21:38:19	Generating Seq2SeqTrainer
21:38:19	Start Training...
21:38:20	Exception: <class 'torch.cuda.OutOfMemoryError'>. CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacty of 7.75 GiB of which 311.38 MiB is free. Including non-PyTorch memory, this process has 4.58 GiB memory in use. Of the allocated memory 4.08 GiB is allocated by PyTorch, and 391.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF. Traceback: <traceback object at 0x7f81ea7d94c0>

Start -- Nov 10 21:39:25 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
21:39:25	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
21:39:27	Using Locally Processed Dataset. Skip Processing...
21:39:27	Generating Seq2SeqTrainer Arguments
21:39:27	Generating Seq2SeqTrainer
21:39:27	Start Training...
22:16:58	Start Saving the model...
22:17:05	Exception: <class 'RuntimeError'>. Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select). Traceback: <traceback object at 0x7f606a7c6ec0>

Start -- Nov 10 22:18:28 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:18:28	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:18:31	Using Locally Processed Dataset. Skip Processing...
22:18:34	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:18:35	Exception: <class 'RuntimeError'>. Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat). Traceback: <traceback object at 0x7fa94bf6ecc0>

Start -- Nov 10 22:19:14 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:19:14	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:19:16	Using Locally Processed Dataset. Skip Processing...
22:19:50	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:19:51	Exception: <class 'RuntimeError'>. Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select). Traceback: <traceback object at 0x7fa9c04cc4c0>

Start -- Nov 10 22:27:51 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:27:51	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:27:53	Using Locally Processed Dataset. Skip Processing...
22:27:56	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:28:09 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:28:09	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:28:11	Using Locally Processed Dataset. Skip Processing...
22:28:14	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:28:34 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:28:34	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:28:37	Using Locally Processed Dataset. Skip Processing...
22:28:39	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:31:52 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:31:52	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:31:54	Using Locally Processed Dataset. Skip Processing...
22:31:54	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:33:35 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:33:35	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:33:37	Using Locally Processed Dataset. Skip Processing...
22:33:45	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:34:16 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:34:16	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:34:18	Using Locally Processed Dataset. Skip Processing...
22:37:12	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:37:41 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:37:41	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:37:43	Using Locally Processed Dataset. Skip Processing...
22:39:21	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:39:39 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:39:39	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:39:41	Using Locally Processed Dataset. Skip Processing...
22:39:52	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 22:40:05 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:40:05	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:40:07	Using Locally Processed Dataset. Skip Processing...
22:40:08	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:40:09	Exception: ['Traceback (most recent call last):\n', '  File "/home/yifanhua/5455-term-project/src/main.py", line 374, in <module>\n    spectrogram = pretrained_model.generate_speech(inputs["input_ids"], speaker_embeddings)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context\n    return func(*args, **kwargs)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2824, in generate_speech\n    return _generate_speech(\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2480, in _generate_speech\n    encoder_out = model.speecht5.encoder(\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 1448, in forward\n    hidden_states = self.prenet(input_values)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 787, in forward\n    inputs_embeds = self.embed_tokens(input_ids)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 162, in forward\n    return F.embedding(\n', '  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 2233, in embedding\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n', 'RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)\n']

Start -- Nov 10 22:43:07 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:43:07	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:43:09	Using Locally Processed Dataset. Skip Processing...
22:43:14	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:43:15	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 374, in <module>
    spectrogram = pretrained_model.generate_speech(inputs["input_ids"], speaker_embeddings)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2824, in generate_speech
    return _generate_speech(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2480, in _generate_speech
    encoder_out = model.speecht5.encoder(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 1448, in forward
    hidden_states = self.prenet(input_values)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 787, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 2233, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)


Start -- Nov 10 22:46:38 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:46:38	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:46:40	Using Locally Processed Dataset. Skip Processing...
22:46:54	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:46:55	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 374, in <module>
    spectrogram = pretrained_model.generate_speech(inputs["input_ids"], speaker_embeddings)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2824, in generate_speech
    return _generate_speech(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2480, in _generate_speech
    encoder_out = model.speecht5.encoder(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 1448, in forward
    hidden_states = self.prenet(input_values)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 787, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 2233, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)


Start -- Nov 10 22:47:34 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:47:34	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:47:36	Using Locally Processed Dataset. Skip Processing...
22:47:37	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:47:38	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 373, in <module>
    spectrogram = pretrained_model.generate_speech(inputs["input_ids"], speaker_embeddings)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2824, in generate_speech
    return _generate_speech(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 2480, in _generate_speech
    encoder_out = model.speecht5.encoder(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 1448, in forward
    hidden_states = self.prenet(input_values)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 787, in forward
    inputs_embeds = self.embed_tokens(input_ids)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 2233, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)


Start -- Nov 10 22:48:28 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:48:28	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:48:30	Using Locally Processed Dataset. Skip Processing...
22:48:41	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:48:42	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 376, in <module>
    speech = vocoder(spectrogram)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 3208, in forward
    spectrogram = (spectrogram - self.mean) / self.scale
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!


Start -- Nov 10 22:52:35 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:52:35	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:52:37	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 225, in <module>
    pretrained_model, processor, tokenizer, speaker_model, data_collator, vocoder = init_global_variables()
  File "/home/yifanhua/5455-term-project/src/main.py", line 86, in init_global_variables
    _processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts").to(device)
AttributeError: 'SpeechT5Processor' object has no attribute 'to'


Start -- Nov 10 22:52:58 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:52:58	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:53:00	Using Locally Processed Dataset. Skip Processing...
22:53:02	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:53:04	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 376, in <module>
    speech = vocoder(spectrogram)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 3208, in forward
    spectrogram = (spectrogram - self.mean) / self.scale
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!


Start -- Nov 10 22:53:37 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:53:37	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:53:39	Using Locally Processed Dataset. Skip Processing...
22:53:40	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:53:41	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 376, in <module>
    speech = vocoder(spectrogram)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/transformers/models/speecht5/modeling_speecht5.py", line 3208, in forward
    spectrogram = (spectrogram - self.mean) / self.scale
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!


Start -- Nov 10 22:53:58 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:53:58	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:54:00	Using Locally Processed Dataset. Skip Processing...
22:54:00	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:54:02	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 380, in <module>
    Audio(speech.numpy(), rate=16000)
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.


Start -- Nov 10 22:55:16 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:55:16	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:55:18	Using Locally Processed Dataset. Skip Processing...
22:55:19	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
22:55:21	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 384, in <module>
    sf.write("output.wav", speech.numpy(), samplerate=16000)
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.


Start -- Nov 10 22:58:12 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
22:58:12	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
22:58:15	Using Locally Processed Dataset. Skip Processing...
22:58:44	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 23:04:34 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
23:04:34	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
23:04:36	Using Locally Processed Dataset. Skip Processing...
23:04:38	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
23:04:39	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 371, in <module>
    example = divided_dataset["test"][5]
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 2803, in __getitem__
    return self._getitem(key)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 2787, in _getitem
    pa_subtable = query_table(self._data, key, indices=self._indices if self._indices is not None else None)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 583, in query_table
    _check_valid_index_key(key, size)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 526, in _check_valid_index_key
    raise IndexError(f"Invalid key: {key} is out of bounds for size {size}")
IndexError: Invalid key: 5 is out of bounds for size 5


Start -- Nov 10 23:04:49 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
23:04:49	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
23:04:51	Using Locally Processed Dataset. Skip Processing...
23:04:53	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39

Start -- Nov 10 23:06:29 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
23:06:29	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
23:06:32	Using Locally Processed Dataset. Skip Processing...
23:06:34	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
23:06:35	Input text: I'm loading the model from the Hugging Face Hub!
23:06:35	Using speaker embedding: tensor([[-7.6836e-02,  6.3403e-02,  4.0562e-02,  3.8820e-02, -1.7536e-02,
          9.0452e-03, -4.9579e-02,  4.5229e-02,  4.2024e-02,  1.4980e-02,
         -7.4401e-02, -8.2151e-02,  4.0258e-02,  3.4921e-02,  3.0220e-02,
          4.3113e-02,  2.8215e-02,  1.8833e-02,  1.4011e-02,  1.5947e-02,
          3.4128e-02,  2.5922e-02, -1.3152e-02, -5.4478e-02, -6.3750e-02,
         -9.2914e-03, -6.7767e-02,  1.5682e-03,  4.6559e-02,  4.0730e-02,
         -3.0536e-03,  5.2462e-02,  4.2241e-02,  1.7429e-03,  2.8580e-02,
         -7.5006e-02,  3.1938e-02,  2.8833e-02,  1.4967e-02, -6.4432e-02,
          1.8939e-02, -9.6601e-03,  2.1530e-02,  5.3108e-02,  4.4103e-02,
         -1.0370e-01, -1.8632e-02,  1.2255e-02, -9.0650e-02,  4.7486e-02,
          2.5308e-02,  2.9944e-02,  1.1476e-02,  3.2961e-02, -8.1554e-02,
         -6.5184e-02,  1.4976e-02,  2.7341e-02,  3.2480e-02,  2.3878e-02,
          1.6458e-02, -7.3298e-03, -1.4582e-02,  1.5723e-02,  3.7580e-02,
          2.4833e-02,  4.5336e-02, -5.6571e-02, -6.9297e-02, -4.3971e-02,
          5.3361e-04,  9.0129e-03,  4.7100e-02,  1.2022e-02,  2.4132e-02,
          4.5285e-02,  8.8045e-03,  2.0786e-02, -5.7390e-02, -6.9695e-02,
         -6.2979e-02, -5.5661e-02, -7.1943e-02, -5.0074e-02, -3.2374e-02,
         -7.4352e-02, -5.9192e-02,  4.9010e-02,  2.1572e-02, -6.5620e-02,
          2.7758e-02, -9.1477e-02,  1.7411e-02, -7.2112e-02,  3.7737e-02,
         -6.9570e-03,  3.6025e-02,  3.9992e-02, -5.8816e-02, -7.7995e-02,
          1.7029e-02, -7.5107e-02, -7.2432e-02,  2.5058e-02,  3.2963e-02,
          2.0084e-02,  4.3422e-02,  6.3396e-02,  2.6535e-02,  2.6281e-02,
         -9.0686e-02,  1.0709e-02,  7.4889e-02,  5.9660e-03,  2.3868e-02,
          5.3681e-02, -6.9733e-02,  5.0336e-03, -5.4502e-02, -1.8466e-03,
          1.7699e-02, -5.9915e-02,  6.1621e-03,  4.6774e-02, -6.2205e-02,
          2.2998e-02, -7.8370e-02,  2.9577e-02,  2.5580e-02,  5.9209e-02,
          2.0903e-02,  3.4895e-02,  1.0720e-02,  6.7392e-02,  2.8271e-02,
         -8.2322e-02, -9.4090e-02,  2.9570e-02, -6.0319e-02,  8.3229e-04,
          3.6323e-02,  1.4722e-03,  1.1924e-02,  6.2906e-02, -6.4020e-02,
          3.6470e-02, -1.3211e-02,  1.3893e-02,  3.0392e-02, -8.4153e-02,
          4.6257e-02, -6.4347e-02, -8.6102e-02,  3.2333e-02,  1.8153e-02,
          1.8537e-02,  2.5648e-02, -8.1804e-02, -7.1273e-02,  5.8943e-02,
          9.4322e-03,  2.1041e-02,  2.3579e-02,  3.5110e-02,  2.9283e-03,
          3.5936e-03,  4.1134e-02,  2.3648e-02,  2.4587e-02,  3.7277e-02,
          1.4844e-02, -6.3547e-02,  6.7236e-03, -7.0230e-02, -3.8990e-02,
          2.2931e-02, -6.3326e-02,  1.6781e-02,  5.9014e-02, -7.7587e-02,
          2.7868e-02, -7.6592e-02,  3.3783e-02,  1.9375e-02, -7.5908e-02,
         -1.0387e-02,  1.4482e-02,  3.2370e-02, -6.6226e-02, -6.2260e-02,
          2.3353e-02,  2.7653e-02, -7.1155e-02,  2.6955e-02,  1.1666e-02,
          2.7088e-02,  1.8777e-02,  1.5794e-02,  3.1896e-02,  5.7146e-03,
          1.7183e-02,  3.0124e-02, -4.7382e-02,  1.3569e-02,  2.6958e-02,
          1.3499e-02,  3.0649e-02,  2.4900e-02,  3.9258e-02,  2.0793e-02,
          3.9824e-03, -7.0943e-02, -5.0493e-02,  4.8370e-02, -6.2684e-02,
          3.4115e-02,  3.9837e-02, -9.1817e-02,  2.9612e-02,  3.2944e-02,
         -6.8549e-02,  3.3213e-02, -7.0979e-02, -3.4610e-02, -7.1876e-02,
          5.6086e-02,  2.0452e-02,  7.0578e-02,  6.3566e-02,  2.9136e-02,
         -1.3794e-02,  6.8589e-02,  2.3369e-02,  1.6955e-02,  6.2187e-03,
          7.6584e-03,  4.0822e-02,  1.8875e-02,  3.2420e-03,  4.5718e-02,
         -5.8132e-02,  2.0638e-02, -9.0662e-02,  2.6839e-02, -6.8926e-02,
          2.6182e-02,  3.1046e-02,  2.3971e-02,  1.9273e-02,  3.9320e-02,
          5.2058e-02,  2.1656e-02,  8.4990e-03, -7.2728e-02,  5.7367e-03,
          4.7709e-02,  1.8558e-02,  4.2686e-02, -4.6847e-02,  5.7891e-02,
          1.9858e-02, -7.3581e-02,  4.9841e-02,  2.3763e-02, -9.7366e-05,
          3.2634e-02,  4.0977e-02,  4.1435e-02,  2.3259e-02,  2.1570e-02,
          2.7965e-02, -3.6707e-03,  6.4330e-03,  4.3431e-02, -8.1272e-02,
          2.1740e-02,  3.4477e-02,  3.4442e-02, -5.8742e-02, -8.1472e-02,
         -2.7763e-02,  3.0170e-02,  5.8892e-02, -7.6027e-02,  3.4409e-02,
          4.3539e-02, -1.2113e-02,  4.0763e-02, -6.8863e-02,  5.1888e-03,
          7.8995e-03,  6.7038e-03,  2.1326e-02, -1.5543e-02,  3.6723e-02,
          2.3226e-02,  2.9182e-02, -9.0791e-03,  3.0437e-02,  5.0427e-02,
         -6.9418e-02,  2.7464e-02,  2.2207e-02, -7.3056e-02,  1.6306e-02,
          3.0963e-02,  2.9017e-02,  2.0750e-02,  3.1957e-02,  2.9078e-02,
          4.5587e-02,  2.0261e-02,  5.0033e-03,  5.8378e-02, -8.4611e-02,
         -7.6075e-02, -1.9838e-02,  4.0487e-02, -6.1888e-02,  4.3652e-02,
         -6.2916e-02,  3.9619e-02, -5.2359e-02,  6.3863e-03,  4.9324e-02,
         -6.9716e-02,  4.2202e-02,  6.4274e-02, -6.0595e-02, -5.6750e-02,
         -6.0675e-02,  2.8630e-02,  2.9104e-02,  4.5632e-02, -8.1962e-02,
          4.5834e-02,  2.8655e-02,  1.9608e-02,  3.6816e-03,  4.6190e-02,
          2.9040e-02, -4.9038e-02,  3.5908e-02,  2.0035e-03, -9.5161e-02,
          1.3396e-02,  3.1781e-02,  2.4335e-02, -5.2164e-02, -7.2463e-02,
         -6.3275e-02,  2.3019e-02, -7.1583e-02,  1.1089e-01,  2.1324e-02,
         -4.8902e-02, -5.4751e-03,  5.0892e-02, -3.2968e-02,  1.6456e-03,
         -1.0364e-01,  1.1794e-02,  2.8560e-03,  3.1179e-02,  5.8883e-02,
         -8.6580e-03, -5.3970e-02,  1.7495e-02,  2.7266e-02,  2.2890e-02,
          5.9171e-03,  3.1879e-02, -5.4221e-02,  7.6534e-03, -1.3825e-02,
         -2.2423e-03,  3.0243e-02,  2.1296e-02,  3.1641e-02,  1.9973e-02,
         -8.4289e-02, -1.0444e-01,  2.8702e-02,  3.7857e-02,  2.3716e-02,
          2.9539e-02,  5.5774e-02, -6.6566e-02,  2.0514e-02,  3.5840e-02,
          1.6014e-02,  1.7473e-02, -4.7530e-02,  2.7591e-02,  2.4982e-02,
         -8.2298e-03,  5.0999e-02, -7.7798e-02,  3.4287e-02, -1.2068e-02,
          1.9090e-03, -5.1682e-02,  9.6981e-03,  2.2473e-02,  3.1747e-02,
          4.2606e-03,  2.0931e-03, -6.1320e-02, -5.2187e-02, -7.9547e-02,
         -4.8807e-02,  3.5517e-02,  3.4056e-02, -1.2789e-02,  4.4212e-02,
         -6.5526e-02,  1.5182e-02, -7.6318e-02, -1.3027e-01, -1.9935e-02,
         -7.3741e-02, -1.0807e-03,  2.6086e-02,  2.6132e-02, -5.8830e-02,
          3.4185e-02,  4.0558e-02,  3.2187e-02,  4.5877e-02, -5.3099e-02,
         -4.2563e-02, -1.2752e-02, -1.9676e-02,  3.6419e-02,  3.3966e-02,
          2.8699e-03,  3.8468e-02,  1.4768e-02,  2.2580e-02, -7.2594e-02,
         -4.6226e-03,  3.8273e-02,  1.4515e-02,  2.8593e-03,  7.1926e-03,
          4.0886e-02,  1.9179e-02,  5.4359e-03,  4.3910e-03, -1.1557e-02,
          3.2949e-02,  1.9718e-02,  3.7592e-02,  4.9951e-02,  4.5965e-02,
          3.4425e-03,  3.8280e-02, -6.6107e-02, -5.9034e-02,  4.0041e-02,
         -1.1044e-02,  3.2420e-03,  2.6370e-02,  3.4795e-02, -7.8728e-02,
          2.9791e-02,  2.5478e-02,  9.7442e-03,  5.1081e-02,  3.3058e-02,
         -2.0060e-03,  4.1954e-02,  2.4819e-03,  5.9872e-03, -5.1906e-02,
         -8.1537e-02,  1.6202e-02, -4.1698e-03,  2.7178e-02,  4.4018e-02,
         -6.4413e-02, -5.9531e-02,  8.8259e-04,  3.8542e-02,  2.8775e-02,
          3.4858e-02, -6.3876e-02,  2.6297e-02, -3.1551e-02, -1.0353e-02,
         -3.4075e-02,  2.4226e-02, -3.8576e-02, -2.3174e-02, -3.1889e-02,
          1.6949e-02, -4.8726e-02,  4.1621e-03, -6.3748e-02, -7.0101e-02,
          7.8505e-03,  4.0942e-02, -6.4920e-02,  3.1049e-02,  5.1092e-03,
         -1.3265e-02,  1.5715e-02,  4.5942e-02,  6.0792e-02, -5.3153e-02,
          3.5526e-02, -6.5377e-02]], device='cuda:0')

Start -- Nov 10 23:08:00 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
23:08:00	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
23:08:03	Using Locally Processed Dataset. Skip Processing...
23:08:03	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
23:08:04	Input text: I'm loading the model from the Hugging Face Hub!

Start -- Nov 11 09:49:03 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
09:49:03	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
09:49:05	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
09:49:32	Finish Loading Remote Dataset. Length of dataset: 8387
09:49:32	Start Setting Sampling Rate to 16 kHz...
09:49:32	Setting Sampling Rate Successfully
09:49:32	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 364, in <module>
    sort_speaker()
TypeError: sort_speaker() missing 1 required positional argument: '_dataset'


Start -- Nov 11 09:49:49 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
09:49:49	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
09:49:51	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
09:50:17	Finish Loading Remote Dataset. Length of dataset: 8387
09:50:17	Start Setting Sampling Rate to 16 kHz...
09:50:17	Setting Sampling Rate Successfully
09:50:18	Start Filtering Short Data
09:50:18	8358 data entries left after filtering
09:50:18	Start Preparing Dataset
09:50:39	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 09:53:21 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
09:53:21	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
09:53:23	Loading Remote Dataset: facebook/voxpopuli. Sub-collection: en_accented
09:53:49	Finish Loading Remote Dataset. Length of dataset: 8387
09:53:49	Start Setting Sampling Rate to 16 kHz...
09:53:49	Setting Sampling Rate Successfully
09:53:49	Start Filtering Short Data
09:53:49	8358 data entries left after filtering
09:53:49	Start Preparing Dataset
09:53:55	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 11:47:35 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
11:47:35	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
11:47:38	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
12:22:59	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 397, in <module>
    # Step 1A: Process & Preparing Dataset
  File "/home/yifanhua/5455-term-project/src/main.py", line 265, in load_remote_dataset
    _dataset = load_dataset(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/load.py", line 2166, in load_dataset
    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/builder.py", line 1190, in as_dataset
    datasets = map_nested(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/utils/py_utils.py", line 456, in map_nested
    return function(data_struct)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/builder.py", line 1220, in _build_single_dataset
    ds = self._as_dataset(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/builder.py", line 1294, in _as_dataset
    dataset_kwargs = ArrowReader(cache_dir, self.info).read(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_reader.py", line 240, in read
    files = self.get_file_instructions(name, instructions, split_infos)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_reader.py", line 213, in get_file_instructions
    file_instructions = make_file_instructions(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_reader.py", line 130, in make_file_instructions
    absolute_instructions = instruction.to_absolute(name2len)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_reader.py", line 653, in to_absolute
    return [_rel_to_abs_instr(rel_instr, name2len) for rel_instr in self._relative_instructions]
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_reader.py", line 653, in <listcomp>
    return [_rel_to_abs_instr(rel_instr, name2len) for rel_instr in self._relative_instructions]
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_reader.py", line 465, in _rel_to_abs_instr
    raise ValueError(f'Unknown split "{split}". Should be one of {list(name2len)}.')
ValueError: Unknown split "validated". Should be one of ['train', 'test', 'validation', 'other', 'invalidated'].


Start -- Nov 11 12:23:47 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
12:23:47	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
12:23:50	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
12:27:15	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 12:27:19 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
12:27:19	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
12:27:22	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
12:32:09	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 13:32:36 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
13:32:36	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
13:32:38	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
13:33:01	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 13:45:53 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
13:45:53	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
13:45:56	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
13:46:07	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 13:46:47 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
13:46:47	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
13:46:50	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
13:58:24	Finish Loading Remote Dataset. Length of dataset: 12135
13:58:24	Begin Sharding the dataset
13:58:24	Total 252 shards
13:58:24	Using Mozilla Common Voice. Additional Cleaning Needed
13:58:24	Starting Size of Mozilla Common Voice: 12135
13:59:05	Size after filtering accent: 8671
13:59:08	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 407, in <module>
    dataset = load_remote_dataset()
  File "/home/yifanhua/5455-term-project/src/main.py", line 281, in load_remote_dataset
    _dataset = list(executor.map(clean_mozilla_dataset(_dataset), _shard_dataset))
  File "/home/yifanhua/5455-term-project/src/main.py", line 250, in clean_mozilla_dataset
    _dataset = _dataset.filter(lambda entry: entry["gender"].isin(['female', 'male']))
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/fingerprint.py", line 511, in wrapper
    out = func(dataset, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3627, in filter
    indices = self.map(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 592, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3097, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3474, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3353, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 6238, in get_indices_from_mask_function
    function(example, indices[i], **fn_kwargs) if with_indices else function(example, **fn_kwargs)
  File "/home/yifanhua/5455-term-project/src/main.py", line 250, in <lambda>
    _dataset = _dataset.filter(lambda entry: entry["gender"].isin(['female', 'male']))
AttributeError: 'str' object has no attribute 'isin'


Start -- Nov 11 13:59:29 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
13:59:29	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
13:59:32	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
13:59:32	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 14:02:27 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
14:02:27	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
14:02:29	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
14:14:06	Finish Loading Remote Dataset. Length of dataset: 12135
14:14:06	Using Mozilla Common Voice. Additional Cleaning Needed
14:14:06	Starting Size of Mozilla Common Voice: 12135
14:14:45	Size after filtering accent: 8671
14:15:12	Size after filtering gender: 8637
14:15:38	Size after filtering voting: 8637
14:15:38	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 410, in <module>
    dataset = load_remote_dataset()
  File "/home/yifanhua/5455-term-project/src/main.py", line 285, in load_remote_dataset
    _dataset = clean_mozilla_dataset(_dataset)
  File "/home/yifanhua/5455-term-project/src/main.py", line 256, in clean_mozilla_dataset
    _dataset = _dataset.map(lambda entry: entry['sentence'].str.lower())
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 592, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3097, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3450, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3353, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/yifanhua/5455-term-project/src/main.py", line 256, in <lambda>
    _dataset = _dataset.map(lambda entry: entry['sentence'].str.lower())
AttributeError: 'str' object has no attribute 'str'


Start -- Nov 11 14:17:45 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
14:17:45	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
14:17:47	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
14:29:20	Finish Loading Remote Dataset. Length of dataset: 5
14:29:20	Using Mozilla Common Voice. Additional Cleaning Needed
14:29:20	Starting Size of Mozilla Common Voice: 5
14:30:28	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 410, in <module>
    dataset = load_remote_dataset()
  File "/home/yifanhua/5455-term-project/src/main.py", line 285, in load_remote_dataset
    _dataset = clean_mozilla_dataset(_dataset)
  File "/home/yifanhua/5455-term-project/src/main.py", line 247, in clean_mozilla_dataset
    _dataset = _dataset.filter(lambda entry: True if entry["accent"] else False)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/dataset_dict.py", line 960, in filter
    {
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/dataset_dict.py", line 961, in <dictcomp>
    k: dataset.filter(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/fingerprint.py", line 511, in wrapper
    out = func(dataset, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3627, in filter
    indices = self.map(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 592, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3097, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3474, in _map_single
    batch = apply_function_on_filtered_inputs(
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3353, in apply_function_on_filtered_inputs
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 6236, in get_indices_from_mask_function
    example = {key: batch[key][i] for key in batch}
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 6236, in <dictcomp>
    example = {key: batch[key][i] for key in batch}
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 272, in __getitem__
    value = self.format(key)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 375, in format
    return self.formatter.format_column(self.pa_table.select([key]))
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 442, in format_column
    column = self.python_features_decoder.decode_column(column, pa_table.column_names[0])
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py", line 218, in decode_column
    return self.features.decode_column(column, column_name) if self.features else column
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/features/features.py", line 1925, in decode_column
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/features/features.py", line 1925, in <listcomp>
    [decode_nested_example(self[column_name], value) if value is not None else None for value in column]
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/features/features.py", line 1325, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/features/audio.py", line 187, in decode_example
    array, sampling_rate = sf.read(f)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/soundfile.py", line 285, in read
    with SoundFile(file, 'r', samplerate, channels,
  File "/home/yifanhua/.local/lib/python3.10/site-packages/soundfile.py", line 658, in __init__
    self._file = self._open(file, mode_int, closefd)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/soundfile.py", line 1216, in _open
    raise LibsndfileError(err, prefix="Error opening {0!r}: ".format(self.name))
soundfile.LibsndfileError: Error opening <_io.BufferedReader name='/home/yifanhua/.cache/huggingface/datasets/downloads/extracted/a62e68ef77daee3e83f95f22b1da75e786c3ec6a96e2f0e5c5288ea4b46ce202/clips/14dadaeff069012e7c585d95f43a504b52a592ea07ff1871caebd698ca80efbfa8a9bffb448fc93ff976516da5c4ee2841852095cca944ef56dc0abdf107fb0d.mp3'>: Format not recognised.


Start -- Nov 11 14:36:54 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
14:36:54	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
14:37:02	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
14:48:36	Finish Loading Remote Dataset. Length of dataset: 5
14:48:36	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 412, in <module>
    if constants.download_remote_dataset:
  File "/home/yifanhua/5455-term-project/src/main.py", line 286, in load_remote_dataset
    # TODO: Remove next line, we dont need to save dataset now. It's just for speeding up the process of debugging
AttributeError: 'NoneType' object has no attribute 'save_to_disk'


Start -- Nov 11 14:52:16 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
14:52:16	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
14:52:18	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
15:03:55	Finish Loading Remote Dataset. Length of dataset: 12135
15:03:56	Using Mozilla Common Voice. Additional Cleaning Needed
15:03:56	Starting Size of Mozilla Common Voice: 12135
15:04:35	Size after filtering accent: 8671
15:05:01	Size after filtering gender: 8637
15:05:28	Size after filtering voting: 8637
15:05:28	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 413, in <module>
    dataset = load_remote_dataset()
  File "/home/yifanhua/5455-term-project/src/main.py", line 288, in load_remote_dataset
    _dataset = clean_mozilla_dataset(_dataset)
  File "/home/yifanhua/5455-term-project/src/main.py", line 256, in clean_mozilla_dataset
    _dataset = _dataset.map(lambda entry: entry['sentence'].lower())
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 592, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 557, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3097, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3450, in _map_single
    example = apply_function_on_filtered_inputs(example, i, offset=offset)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3364, in apply_function_on_filtered_inputs
    validate_function_output(processed_inputs, indices)
  File "/home/yifanhua/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py", line 3309, in validate_function_output
    raise TypeError(
TypeError: Provided `function` which is applied to all elements of table returns a variable of type <class 'str'>. Make sure provided `function` returns a variable of type `dict` (or a pyarrow table) to update the dataset or `None` if you are only interested in side effects.


Start -- Nov 11 17:10:50 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
17:10:50	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
17:10:52	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
17:11:01	KeyboardInterrupt detected. Exiting...

Start -- Nov 11 17:11:05 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
17:11:05	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
17:11:08	Using Locally Processed Dataset. Skip Processing...
17:11:08	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
17:11:09	Input text: I'm loading the model from the Hugging Face Hub!
17:11:09	Exception: Traceback (most recent call last):
  File "/home/yifanhua/5455-term-project/src/main.py", line 440, in <module>
    speaker_embeddings = torch.tensor(example["speaker_embeddings"]).unsqueeze(0).to(device)
KeyError: 'speaker_embeddings'


Start -- Nov 11 17:11:49 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
17:11:49	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
17:11:52	Loading Remote Dataset: mozilla-foundation/common_voice_1_0. Sub-collection: en
17:23:25	Finish Loading Remote Dataset. Length of dataset: 12135
17:23:26	Using Mozilla Common Voice. Additional Cleaning Needed
17:23:26	Starting Size of Mozilla Common Voice: 12135
17:24:05	Size after filtering accent: 8671
17:24:32	Size after filtering gender: 8637
17:24:58	Size after filtering voting: 8637
17:24:59	Finish normalizing input text
17:24:59	Finish Cleaning Dataset. Length of dataset: 8637
17:24:59	Start Setting Sampling Rate to 16 kHz...
17:24:59	Setting Sampling Rate Successfully
17:24:59	Start Filtering Short Data
17:24:59	8635 data entries left after filtering
17:24:59	Start Preparing Dataset
17:27:40	Preparing dataset finished successfully
17:27:40	Start Filtering Long Data
17:27:40	8635 data entries left after filtering
17:27:40	save_processed_dataset is True. Saving processed dataset to dir: ./data/
17:27:41	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
17:27:42	Input text: I'm loading the model from the Hugging Face Hub!

Start -- Nov 11 19:11:38 -- pytorch=2.1.0+cu121, device=cuda, cpu_count=48
19:11:38	Initializing pretrained model, processor, tokenizer, speaker_model, data_collator, and vocoder
19:11:40	Using Locally Processed Dataset. Skip Processing...
19:11:40	Using model: ./model/trained_yifanhua-threadripper_Nov10_21:39
19:11:41	Input text: I'm loading the model from the Hugging Face Hub!
